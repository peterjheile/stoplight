{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds all of the filepaths\n",
    "train_path = \"datasets\\\\cropped_lisa_1\\\\train_1\"\n",
    "test_path = \"datasets\\\\cropped_lisa_1\\\\val_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "\n",
    "for instance in os.listdir(train_path):\n",
    "    for im in os.listdir(train_path + \"\\\\\" + instance):\n",
    "\n",
    "        image = Image.open(train_path + \"\\\\\" + instance+ \"\\\\\" + im)\n",
    "        image = np.array(image.resize((64,64)))\n",
    "        image = list(image.reshape(64,64,3))\n",
    "        \n",
    "        if instance == \"go\": \n",
    "            train_data.append(image)\n",
    "            test_data.append([1,0,0])\n",
    "        elif instance == \"warning\" : \n",
    "            train_data.append(image)\n",
    "            test_data.append([0,1,0])\n",
    "        elif instance == \"stop\": \n",
    "            train_data.append(image)\n",
    "            test_data.append([0,0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28690, 64, 64, 3) (28690, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28690, 64, 64, 3) (28690, 3)\n",
      "NORMALIZED PIXEL VALUES: [[[0.08235294 0.07058824 0.15294118]\n",
      "  [0.08235294 0.07058824 0.15294118]\n",
      "  [0.08235294 0.07058824 0.15294118]\n",
      "  ...\n",
      "  [0.14117647 0.20392157 0.20392157]\n",
      "  [0.14901961 0.21176471 0.21176471]\n",
      "  [0.14901961 0.21176471 0.21176471]]\n",
      "\n",
      " [[0.08235294 0.07058824 0.15294118]\n",
      "  [0.08235294 0.07058824 0.15294118]\n",
      "  [0.08235294 0.07058824 0.15294118]\n",
      "  ...\n",
      "  [0.14117647 0.20392157 0.20392157]\n",
      "  [0.14901961 0.21176471 0.21176471]\n",
      "  [0.14901961 0.21176471 0.21176471]]\n",
      "\n",
      " [[0.08235294 0.07058824 0.15294118]\n",
      "  [0.08235294 0.07058824 0.15294118]\n",
      "  [0.08235294 0.07058824 0.15294118]\n",
      "  ...\n",
      "  [0.14117647 0.20392157 0.20392157]\n",
      "  [0.14901961 0.21176471 0.21176471]\n",
      "  [0.14901961 0.21176471 0.21176471]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.05882353 0.06666667 0.05098039]\n",
      "  [0.05882353 0.06666667 0.05098039]\n",
      "  [0.05882353 0.06666667 0.05098039]\n",
      "  ...\n",
      "  [0.14509804 0.19607843 0.23137255]\n",
      "  [0.15294118 0.20392157 0.23921569]\n",
      "  [0.15686275 0.20784314 0.23921569]]\n",
      "\n",
      " [[0.05882353 0.06666667 0.04705882]\n",
      "  [0.05882353 0.06666667 0.04705882]\n",
      "  [0.05882353 0.06666667 0.04705882]\n",
      "  ...\n",
      "  [0.14509804 0.19607843 0.23137255]\n",
      "  [0.15294118 0.20392157 0.23921569]\n",
      "  [0.15686275 0.20784314 0.23921569]]\n",
      "\n",
      " [[0.05882353 0.06666667 0.04705882]\n",
      "  [0.05882353 0.06666667 0.04705882]\n",
      "  [0.05882353 0.06666667 0.04705882]\n",
      "  ...\n",
      "  [0.14509804 0.19607843 0.23137255]\n",
      "  [0.15294118 0.20392157 0.23921569]\n",
      "  [0.15686275 0.20784314 0.23921569]]]\n"
     ]
    }
   ],
   "source": [
    "#normalize to 0-1 for every pixel value\n",
    "train_data = train_data/255\n",
    "print(train_data.shape, test_data.shape)\n",
    "print(\"NORMALIZED PIXEL VALUES:\", train_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(train_data)\n",
    "\n",
    "#Use 80/20 split for training/testing\n",
    "train_ration = .8\n",
    "test_ratio = .2\n",
    "\n",
    "total_samples = train_data.shape[0]\n",
    "train_samples_count = int(.8 * total_samples)\n",
    "val_samples_count = int(.2 * total_samples)\n",
    "\n",
    "x_train = train_data[:train_samples_count]\n",
    "x_val = train_data[train_samples_count:]\n",
    "\n",
    "y_train = test_data[:train_samples_count]\n",
    "y_val = test_data[train_samples_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28690, 64, 64, 3)\n",
      "(22952, 64, 64, 3) (22952, 3)\n",
      "(5738, 64, 64, 3) (5738, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model creation\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation = \"relu\", input_shape = (64,64,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation = \"relu\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation = \"relu\"),\n",
    "    layers.Dense(3, activation= \"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2869/2869 [==============================] - 238s 82ms/step - loss: 0.6916 - accuracy: 0.5539 - val_loss: 2.2201 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2869/2869 [==============================] - 209s 73ms/step - loss: 0.6870 - accuracy: 0.5594 - val_loss: 2.0791 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2869/2869 [==============================] - 196s 68ms/step - loss: 0.6867 - accuracy: 0.5594 - val_loss: 2.2147 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2869/2869 [==============================] - 192s 67ms/step - loss: 0.6866 - accuracy: 0.5594 - val_loss: 2.3793 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2869/2869 [==============================] - 239s 83ms/step - loss: 0.6864 - accuracy: 0.5594 - val_loss: 2.6833 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs = 5, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_final_x = []\n",
    "validation_final_y = []\n",
    "\n",
    "test_size = 1000\n",
    "\n",
    "for instance in os.listdir(test_path):\n",
    "    counter = 0\n",
    "    for im in os.listdir(test_path + \"\\\\\" + instance):\n",
    "        counter+=1\n",
    "        if counter%(test_size//3) == 0:\n",
    "            break\n",
    "        image = Image.open(test_path + \"\\\\\" + instance+ \"\\\\\" + im)\n",
    "        image = np.array(image.resize((64,64)))\n",
    "        image = list(image.reshape(64,64,3))\n",
    "        \n",
    "        if instance == \"go\": \n",
    "            validation_final_x.append(image)\n",
    "            validation_final_y.append(0)\n",
    "        elif instance == \"warning\" : \n",
    "            validation_final_x.append(image)\n",
    "            validation_final_y.append(1)\n",
    "        elif instance == \"stop\": \n",
    "            validation_final_x.append(image)\n",
    "            validation_final_y.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(772, 64, 64, 3) (772,)\n"
     ]
    }
   ],
   "source": [
    "#count of final test \n",
    "validation_final_x = np.array(validation_final_x)\n",
    "validation_final_y = np.array(validation_final_y)\n",
    "print(validation_final_x.shape, validation_final_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 17ms/step\n",
      "(772,)\n"
     ]
    }
   ],
   "source": [
    "#finding accuracy of final testing\n",
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict(validation_final_x)\n",
    "predicted_labels = np.argmax(predictions, axis = 1)\n",
    "print(predicted_labels.shape)\n",
    "accuracy = accuracy_score(predicted_labels, validation_final_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4961139896373057\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompVisionClass",
   "language": "python",
   "name": "compvisionclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
